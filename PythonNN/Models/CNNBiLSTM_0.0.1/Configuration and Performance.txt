Confusion Matrix:
 [[22  0  0  1  0  0  0  1  0  0  0]
 [ 1 14 12  2  0  0  4  0  0  0  0]
 [ 0  8 11  0  0  0  2  0  1  1  1]
 [ 1  1  0 11 18  0  3  1  0  0  0]
 [ 1  1  1  6  9  0  4  0  0  0  0]
 [ 0  1  0  4  0 10 12  0  0  0  0]
 [ 0  1  0  2  2  5 19  0  0  1  0]
 [ 1  0  0  0  1  0  2  9 16  1  0]
 [ 0  0  0  0  0  1  1  6 24  0  1]
 [ 1  0  1  0  0  0  0  0  1 33 18]
 [ 0  0  1  0  0  0  0  0  2 12 31]]

Classification Report:
               precision    recall  f1-score   support

           0      0.815     0.917     0.863        24
           1      0.538     0.424     0.475        33
           2      0.423     0.458     0.440        24
           3      0.423     0.314     0.361        35
           4      0.300     0.409     0.346        22
           5      0.625     0.370     0.465        27
           6      0.404     0.633     0.494        30
           7      0.529     0.300     0.383        30
           8      0.545     0.727     0.623        33
           9      0.688     0.611     0.647        54
          10      0.608     0.674     0.639        46

    accuracy                          0.539       358
   macro avg      0.536     0.531     0.521       358
weighted avg      0.550     0.539     0.533       358


Model:

class CNNBiLSTMClassifier(nn.Module):
    def __init__(self, num_classes=11):
        super(CNNBiLSTMClassifier, self).__init__()

        self.cnn = nn.Sequential(
            nn.Conv1d(4, 32, kernel_size=5, padding=2),
            nn.BatchNorm1d(32),
            nn.ReLU(),
            nn.MaxPool1d(2),
            nn.Conv1d(32, 64, kernel_size=5, padding=2),
            nn.BatchNorm1d(64),
            nn.ReLU(),
            nn.MaxPool1d(2)
        )

        self.lstm = nn.LSTM(input_size=64, hidden_size=32, batch_first=True, bidirectional=True)
        
        self.bn = nn.BatchNorm1d(32 * 2)  # Match hidden size
        
        self.classifier = nn.Sequential(
            nn.Linear(32 * 2, 32),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(32, num_classes)
        )

    def forward(self, x):
        x = self.cnn(x)  # â†’ (B, 64, T)
        x = x.permute(0, 2, 1)  # (B, T, 64)

        _, (hn, _) = self.lstm(x)  # hn: (2, B, 32) if bidirectional=True
        hn = torch.cat((hn[0], hn[1]), dim=1)  # (B, 64)

        hn = self.bn(hn)  # BatchNorm on full concatenated hidden state
        return self.classifier(hn)


Features: Raw Data Normalized

Epochs: 1000